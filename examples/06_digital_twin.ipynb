{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 Event Generation\n",
    "\n",
    "This notebook contains examples on how to generate cascades, tracks and starting tracks with the Olympus software package.\n",
    "\n",
    "First, we got to import some packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from ananke.configurations.collection import (\n",
    "    HDF5StorageConfiguration,\n",
    "    MergeConfiguration, MergeContentConfiguration,\n",
    ")\n",
    "from ananke.configurations.events import (\n",
    "    RedistributionConfiguration,\n",
    "    Interval,\n",
    "    EventRedistributionMode,\n",
    ")\n",
    "from ananke.visualisation.event import draw_hit_histogram, draw_hit_distribution\n",
    "from ananke.visualisation.detector import get_detector_scatter3ds\n",
    "from olympus.configuration.generators import (\n",
    "    EventGeneratorConfiguration,\n",
    "    NoiseGeneratorConfiguration,\n",
    ")\n",
    "from olympus.configuration.generators import GenerationConfiguration\n",
    "from olympus.event_generation.medium import MediumEstimationVariant\n",
    "from olympus.configuration.generators import UniformSpectrumConfiguration\n",
    "from ananke.models.collection import Collection\n",
    "from ananke.schemas.event import EventType, NoiseType, RecordType\n",
    "from olympus.configuration.photon_propagation import MockPhotonPropagatorConfiguration\n",
    "\n",
    "from olympus.configuration.generators import DatasetConfiguration\n",
    "from olympus.configuration.generators import BioluminescenceGeneratorConfiguration\n",
    "\n",
    "from ananke.configurations.presets.detector import single_line_configuration\n",
    "from olympus.event_generation.generators import generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the configuration\n",
    "\n",
    "To create events, we need a detector, a photon propagation, and a storage configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_configuration = single_line_configuration\n",
    "data_path = 'data/example/06_digital_twin.h5'\n",
    "merged_data_path = 'data/example/06_digital_twin_merged.h5'\n",
    "\n",
    "storage_configuration = HDF5StorageConfiguration(\n",
    "    data_path=data_path,\n",
    "    read_only=False\n",
    ")\n",
    "\n",
    "merged_storage_configuration = HDF5StorageConfiguration(\n",
    "    data_path=merged_data_path,\n",
    "    read_only=False\n",
    ")\n",
    "\n",
    "# This is optional\n",
    "photon_propagator_configuration = MockPhotonPropagatorConfiguration(\n",
    "    resolution=18000,\n",
    "    medium=MediumEstimationVariant.PONE_OPTIMISTIC,\n",
    "    max_memory_usage=int(2147483648 / 4)  # Great to overcome memory issues\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, we define our generation configurations for all types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cascade_generation_configuration = GenerationConfiguration(\n",
    "    generator=EventGeneratorConfiguration(\n",
    "        type=EventType.CASCADE,\n",
    "        spectrum=UniformSpectrumConfiguration(\n",
    "            log_minimal_energy=2.0,\n",
    "            log_maximal_energy=5.5\n",
    "        ),\n",
    "        source_propagator=photon_propagator_configuration\n",
    "    ),\n",
    "    number_of_samples=3\n",
    ")\n",
    "\n",
    "noise_generator_config = NoiseGeneratorConfiguration(\n",
    "    type=NoiseType.ELECTRICAL,\n",
    "    start_time=0,\n",
    "    duration=1000,\n",
    ")\n",
    "\n",
    "noise_generation_configuration = GenerationConfiguration(\n",
    "    generator=noise_generator_config,\n",
    "    append=True,\n",
    "    number_of_samples=10\n",
    "),\n",
    "\n",
    "bioluminescence_generation_configuration = GenerationConfiguration(\n",
    "    generator=BioluminescenceGeneratorConfiguration(\n",
    "        type=NoiseType.BIOLUMINESCENCE,\n",
    "        start_time=0,\n",
    "        duration=1000,\n",
    "        julia_data_path='../../data/biolumi_sims',\n",
    "        batch_size=48\n",
    "    ),\n",
    "    append=True,\n",
    "    number_of_samples=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = DatasetConfiguration(\n",
    "    detector=detector_configuration,\n",
    "    generators=[\n",
    "        cascade_generation_configuration,\n",
    "        GenerationConfiguration(\n",
    "            generator=noise_generator_config,\n",
    "            append=True,\n",
    "            number_of_samples=10\n",
    "        ),\n",
    "        bioluminescence_generation_configuration,\n",
    "    ],\n",
    "    storage=storage_configuration\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the collection\n",
    "\n",
    "Once, you have the complete configuration, creating the events is simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional, but to keep the data lean\n",
    "try:\n",
    "    os.remove(data_path)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "collection = generate(configuration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'collection' not in globals():\n",
    "    collection = Collection(storage_configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the events\n",
    "\n",
    "Now, as a next step, we want to combine the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_configuration = MergeConfiguration(\n",
    "    in_collections=[storage_configuration],\n",
    "    out_collection=merged_storage_configuration,\n",
    "    content=[\n",
    "        MergeContentConfiguration(\n",
    "            primary_type=RecordType.CASCADE,\n",
    "            secondary_types=[\n",
    "                RecordType.ELECTRICAL,\n",
    "                RecordType.BIOLUMINESCENCE\n",
    "            ],\n",
    "            interval=Interval(),\n",
    "            number_of_records=3\n",
    "        ),\n",
    "        MergeContentConfiguration(\n",
    "            primary_type=RecordType.BIOLUMINESCENCE,\n",
    "            secondary_types=[\n",
    "                RecordType.ELECTRICAL\n",
    "            ],\n",
    "            interval=Interval(),\n",
    "            number_of_records=3\n",
    "        )\n",
    "    ],\n",
    "    redistribution=RedistributionConfiguration(\n",
    "        interval=Interval(),\n",
    "        mode=EventRedistributionMode.CONTAINS_PERCENTAGE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_collection = Collection.from_merge(merge_configuration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Event images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with merged_collection:\n",
    "    records = merged_collection.storage.get_records()\n",
    "    hits = merged_collection.storage.get_hits()\n",
    "    sources = merged_collection.storage.get_sources()\n",
    "    detector = merged_collection.storage.get_detector()\n",
    "\n",
    "records.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'data/digital_twin_images/'\n",
    "isExist = os.path.exists(image_path)\n",
    "\n",
    "if not isExist:\n",
    "    # Create a new directory because it does not exist\n",
    "    os.makedirs(image_path)\n",
    "\n",
    "for record_id in records.record_ids:\n",
    "    record = records.get_by_record_ids(record_id)\n",
    "    record_hits = hits.get_by_record_ids(record_id)\n",
    "    record_sources = sources.get_by_record_ids(record_id)\n",
    "    fig = draw_hit_distribution(record_hits)\n",
    "    fig.savefig(\n",
    "        os.path.join(image_path, 'record_{}_distribution.png').format(record_id),\n",
    "        dpi=300\n",
    "    )\n",
    "    fig = draw_hit_histogram(record_hits, detector)\n",
    "    fig.savefig(\n",
    "        os.path.join(image_path, 'record_{}_histogram.png').format(record_id),\n",
    "        dpi=300\n",
    "    )\n",
    "    fig = get_detector_scatter3ds(\n",
    "        detector,\n",
    "        include_modules=False,\n",
    "        include_pmts=True,\n",
    "        hits=record_hits,\n",
    "        sources=record_sources\n",
    "    )\n",
    "    fig.write_image(\n",
    "        os.path.join(image_path, 'record_{}_3d.png').format(record_id),\n",
    "        scale=2\n",
    "    )\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
